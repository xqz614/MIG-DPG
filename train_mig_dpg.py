#!/usr/bin/env python3
"""
MIG-DPG å®Œæ•´è®­ç»ƒè„šæœ¬
åŒ…å«æ•°æ®åŠ è½½ã€æ¨¡å‹åˆ›å»ºã€è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹
"""

import argparse
import torch
import torch.nn as nn
import random
import numpy as np
import os
import sys
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(__file__))

from mig_dpg.models.mig_dpg_model import MIG_DPG_Model
from mig_dpg.configs.mig_dpg_default_config import MIG_DPG_DefaultConfig
from mig_dpg.trainer import MIG_DPG_Trainer
from mig_dpg.data_processor import MIG_DPG_DataProcessor


def set_seed(seed: int):
    """è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='MIG-DPG Training Script')
    
    # åŸºç¡€å‚æ•°
    parser.add_argument('--dataset', type=str, default='baby', 
                       choices=['baby', 'sports', 'clothing', 'elec'],
                       help='Dataset name')
    parser.add_argument('--gpu_id', type=int, default=0, help='GPU ID to use')
    parser.add_argument('--seed', type=int, default=42, help='Random seed')
    parser.add_argument('--epochs', type=int, default=100, help='Number of epochs')
    parser.add_argument('--batch_size', type=int, default=512, help='Batch size')
    parser.add_argument('--learning_rate', type=float, default=1e-3, help='Learning rate')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--embedding_size', type=int, default=64, help='Embedding dimension')
    parser.add_argument('--k_e', type=int, default=4, help='Embedding modality hops')
    parser.add_argument('--k_t', type=int, default=2, help='Text modality hops')
    parser.add_argument('--k_v', type=int, default=1, help='Vision modality hops')
    
    # è®­ç»ƒç­–ç•¥
    parser.add_argument('--training_strategy', type=str, default='joint',
                       choices=['joint', 'sequential', 'curriculum'],
                       help='Training strategy')
    parser.add_argument('--dpo_weight', type=float, default=0.5, 
                       help='DPO loss weight')
    parser.add_argument('--generation_weight', type=float, default=0.3,
                       help='Generation loss weight')
    
    # æ•°æ®å‚æ•°
    parser.add_argument('--preference_data_ratio', type=float, default=0.3,
                       help='Ratio of preference data to generate')
    parser.add_argument('--synthetic_explanation', action='store_true',
                       help='Use synthetic explanation data')
    
    # ä¿å­˜å’Œæ—¥å¿—
    parser.add_argument('--save_model', action='store_true', default=True,
                       help='Save model checkpoints')
    parser.add_argument('--model_save_path', type=str, default='./saved_models/',
                       help='Path to save models')
    parser.add_argument('--experiment_name', type=str, default=None,
                       help='Experiment name for logging')
    
    return parser.parse_args()


def create_experiment_name(args):
    """åˆ›å»ºå®éªŒåç§°"""
    if args.experiment_name:
        return args.experiment_name
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    experiment_name = f"MIG_DPG_{args.dataset}_{args.training_strategy}_{timestamp}"
    return experiment_name


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_arguments()
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(f'cuda:{args.gpu_id}' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºå®éªŒåç§°
    experiment_name = create_experiment_name(args)
    print(f"å®éªŒåç§°: {experiment_name}")
    
    # åˆ›å»ºé…ç½®
    config = MIG_DPG_DefaultConfig()
    
    # æ›´æ–°é…ç½®
    config.dataset = args.dataset
    config.gpu_id = args.gpu_id
    config.seed = args.seed
    config.epochs = args.epochs
    config.batch_size = args.batch_size
    config.learning_rate = args.learning_rate
    config.embedding_size = args.embedding_size
    config.k_e = args.k_e
    config.k_t = args.k_t
    config.k_v = args.k_v
    config.training_strategy = args.training_strategy
    config.dpo_weight = args.dpo_weight
    config.generation_weight = args.generation_weight
    config.preference_data_ratio = args.preference_data_ratio
    config.synthetic_explanation = args.synthetic_explanation
    config.save_model = args.save_model
    config.model_save_path = os.path.join(args.model_save_path, experiment_name)
    
    # æ ¹æ®æ•°æ®é›†è°ƒæ•´é…ç½®
    config.get_dataset_specific_config(args.dataset)
    
    # æ‰“å°é…ç½®
    print("\n" + "="*60)
    print("MIG-DPG è®­ç»ƒé…ç½®")
    print("="*60)
    config.print_config()
    
    # åˆ›å»ºæ•°æ®å¤„ç†å™¨
    print("\n" + "="*60)
    print("æ•°æ®å‡†å¤‡")
    print("="*60)
    data_processor = MIG_DPG_DataProcessor(config)
    
    # åŠ è½½æ•°æ®
    data = data_processor.load_data(config.dataset)
    
    # æ›´æ–°é…ç½®ä¸­çš„æ•°æ®ç»Ÿè®¡
    config.num_users = data['num_users']
    config.num_items = data['num_items']
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset, val_dataset, test_dataset = data_processor.create_datasets(data)
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataloader, val_dataloader, test_dataloader = data_processor.create_dataloaders(
        train_dataset, val_dataset, test_dataset
    )
    
    # åˆ›å»ºæ¨¡å‹
    print("\n" + "="*60)
    print("æ¨¡å‹åˆ›å»º")
    print("="*60)
    model = MIG_DPG_Model(config)
    
    # æ¨¡å‹ç»Ÿè®¡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    print(f"æ¨¡å‹æ€»å‚æ•°: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = MIG_DPG_Trainer(model, config, device)
    
    # å¼€å§‹è®­ç»ƒ
    print("\n" + "="*60)
    print("å¼€å§‹è®­ç»ƒ")
    print("="*60)
    
    try:
        training_history = trainer.train(train_dataloader, val_dataloader)
        
        # è®­ç»ƒå®Œæˆåçš„æœ€ç»ˆè¯„ä¼°
        print("\n" + "="*60)
        print("æœ€ç»ˆè¯„ä¼°")
        print("="*60)
        
        final_metrics = trainer.evaluate(test_dataloader)
        print("æµ‹è¯•é›†æœ€ç»ˆç»“æœ:")
        for metric, value in final_metrics.items():
            print(f"  {metric}: {value:.4f}")
        
        # ä¿å­˜è®­ç»ƒå†å²
        if config.save_model:
            import json
            history_path = os.path.join(config.model_save_path, 'training_history.json')
            
            # è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
            serializable_history = {}
            for key, value in training_history.items():
                if isinstance(value, list) and len(value) > 0:
                    if isinstance(value[0], dict):
                        # å¤„ç†åµŒå¥—å­—å…¸
                        serializable_history[key] = [
                            {k: float(v) if torch.is_tensor(v) else v for k, v in item.items()}
                            for item in value
                        ]
                    else:
                        serializable_history[key] = [float(v) if torch.is_tensor(v) else v for v in value]
                else:
                    serializable_history[key] = value
            
            with open(history_path, 'w') as f:
                json.dump(serializable_history, f, indent=2)
            print(f"è®­ç»ƒå†å²å·²ä¿å­˜åˆ°: {history_path}")
        
        # ä¿å­˜æœ€ç»ˆæŒ‡æ ‡
        final_results = {
            'experiment_name': experiment_name,
            'config': config.__dict__,
            'final_metrics': final_metrics,
            'best_performance': trainer.best_performance,
            'total_epochs': trainer.current_epoch
        }
        
        if config.save_model:
            results_path = os.path.join(config.model_save_path, 'final_results.json')
            with open(results_path, 'w') as f:
                json.dump(final_results, f, indent=2, default=str)
            print(f"æœ€ç»ˆç»“æœå·²ä¿å­˜åˆ°: {results_path}")
        
        print("\n" + "="*60)
        print("è®­ç»ƒå®Œæˆ! ğŸ‰")
        print("="*60)
        print(f"æœ€ä½³æ€§èƒ½: {trainer.best_performance:.4f}")
        print(f"æ€»è®­ç»ƒè½®æ•°: {trainer.current_epoch}")
        
        # ç”Ÿæˆä¸€äº›æ¨èç¤ºä¾‹
        print("\næ¨èç¤ºä¾‹:")
        model.eval()
        with torch.no_grad():
            sample_data = next(iter(test_dataloader))
            sample_users = sample_data['user_embeddings'][:5]  # å–å‰5ä¸ªç”¨æˆ·
            
            recommendations = model.predict_recommendations(
                g=sample_data['graph'],
                user_embeddings=sample_users,
                item_v_feat=sample_data['item_v_feat'],
                item_t_feat=sample_data['item_t_feat'],
                item_embeddings=sample_data['item_embeddings'],
                topk=10
            )
            
            for i, rec_list in enumerate(recommendations):
                top5_items = rec_list[:5].tolist()
                print(f"  ç”¨æˆ· {i}: {top5_items}")
                
        # ç”Ÿæˆè§£é‡Šç¤ºä¾‹
        if config.generation_enabled:
            print("\nè§£é‡Šç”Ÿæˆç¤ºä¾‹:")
            target_items = recommendations[:3, 0]  # æ¯ä¸ªç”¨æˆ·çš„ç¬¬ä¸€ä¸ªæ¨è
            
            explanations = model.generate_explanations(
                g=sample_data['graph'],
                user_embeddings=sample_users[:3],
                item_v_feat=sample_data['item_v_feat'],
                item_t_feat=sample_data['item_t_feat'],
                target_items=target_items,
                item_embeddings=sample_data['item_embeddings']
            )
            
            for i, explanation in enumerate(explanations):
                tokens_preview = explanation[:10]
                print(f"  ç”¨æˆ· {i} â†’ ç‰©å“ {target_items[i].item()}: {tokens_preview}")
        
    except KeyboardInterrupt:
        print("\nè®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        if trainer.best_performance > 0:
            print(f"å½“å‰æœ€ä½³æ€§èƒ½: {trainer.best_performance:.4f}")
    except Exception as e:
        print(f"\nè®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
    
    print("\nç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main() 