#!/usr/bin/env python3
"""
MIG-DPG ç»„ä»¶å•ç‹¬æµ‹è¯•è„šæœ¬
åˆ†åˆ«æµ‹è¯•æ¯ä¸ªç»„ä»¶ï¼Œé¿å…DGLä¾èµ–é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import sys
import os
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

def test_dpo_layer_direct():
    """ç›´æ¥æµ‹è¯•DPOå±‚åŠŸèƒ½"""
    print("=" * 50)
    print("ğŸ§ª ç›´æ¥æµ‹è¯•DPOåå¥½ä¼˜åŒ–å±‚")
    print("=" * 50)
    
    try:
        # ç›´æ¥å¯¼å…¥DPOå±‚ç±»å®šä¹‰
        sys.path.insert(0, os.path.join(current_dir, 'mig_dpg', 'layers'))
        from dpo_layer import DPOLayer
        
        # åˆ›å»ºDPOå±‚
        embedding_dim = 64
        dpo_layer = DPOLayer(
            embedding_dim=embedding_dim,
            hidden_dim=128,
            beta=0.1,
            dropout=0.1,
            num_heads=4
        )
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 32
        num_items = 100
        
        user_embeddings = torch.randn(batch_size, embedding_dim)
        item_embeddings = torch.randn(num_items, embedding_dim)
        positive_items = torch.randint(0, num_items, (batch_size,))
        negative_items = torch.randint(0, num_items, (batch_size,))
        
        print(f"è¾“å…¥æ•°æ®å½¢çŠ¶:")
        print(f"  ç”¨æˆ·åµŒå…¥: {user_embeddings.shape}")
        print(f"  ç‰©å“åµŒå…¥: {item_embeddings.shape}")
        print(f"  æ­£æ ·æœ¬ID: {positive_items.shape}")
        print(f"  è´Ÿæ ·æœ¬ID: {negative_items.shape}")
        
        # å‰å‘ä¼ æ’­
        enhanced_user_emb, preference_scores = dpo_layer(
            user_embeddings, item_embeddings, positive_items, negative_items
        )
        
        print(f"è¾“å‡ºç»“æœ:")
        print(f"  å¢å¼ºç”¨æˆ·åµŒå…¥: {enhanced_user_emb.shape}")
        print(f"  æ­£æ ·æœ¬åå¥½åˆ†æ•°: {preference_scores['pos_policy'].shape}")
        print(f"  è´Ÿæ ·æœ¬åå¥½åˆ†æ•°: {preference_scores['neg_policy'].shape}")
        
        # è®¡ç®—DPOæŸå¤±
        dpo_loss = dpo_layer.compute_dpo_loss(preference_scores)
        print(f"âœ… DPOæŸå¤±: {dpo_loss:.4f}")
        
        # æµ‹è¯•åå¥½æ’åº
        preference_matrix = dpo_layer.get_preference_ranking(user_embeddings[:5], item_embeddings)
        print(f"åå¥½æ’åºçŸ©é˜µ: {preference_matrix.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ DPOå±‚æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_generation_layer_direct():
    """ç›´æ¥æµ‹è¯•ç”Ÿæˆå±‚åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ§ª ç›´æ¥æµ‹è¯•ç”Ÿæˆå¼è§£é‡Šå±‚")
    print("=" * 50)
    
    try:
        # ç›´æ¥å¯¼å…¥ç”Ÿæˆå±‚ç±»å®šä¹‰
        sys.path.insert(0, os.path.join(current_dir, 'mig_dpg', 'layers'))
        from generation_layer import GenerativeExplanationLayer, MultiModalFusion
        
        # åˆ›å»ºç”Ÿæˆå±‚
        gen_layer = GenerativeExplanationLayer(
            embedding_dim=64,
            text_dim=384,
            vision_dim=2048,
            hidden_dim=128,
            vocab_size=1000,
            max_length=50,
            num_layers=2,
            num_heads=4,
            dropout=0.1
        )
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 16
        num_items = 50
        
        user_embeddings = torch.randn(batch_size, 64)
        item_embeddings = torch.randn(num_items, 64)
        item_text_features = torch.randn(num_items, 384)
        item_vision_features = torch.randn(num_items, 2048)
        target_items = torch.randint(0, num_items, (batch_size,))
        target_sequence = torch.randint(0, 1000, (batch_size, 20))
        
        print(f"è¾“å…¥æ•°æ®å½¢çŠ¶:")
        print(f"  ç”¨æˆ·åµŒå…¥: {user_embeddings.shape}")
        print(f"  ç‰©å“åµŒå…¥: {item_embeddings.shape}")
        print(f"  ç›®æ ‡åºåˆ—: {target_sequence.shape}")
        
        # è®­ç»ƒæ¨¡å¼ - è®¡ç®—æŸå¤±
        gen_layer.train()
        outputs = gen_layer(
            user_embeddings=user_embeddings,
            item_embeddings=item_embeddings,
            item_text_features=item_text_features,
            item_vision_features=item_vision_features,
            target_items=target_items,
            explanation_tokens=target_sequence
        )
        
        # è®¡ç®—æŸå¤±
        logits = outputs['logits']
        loss = gen_layer.compute_generation_loss(logits, target_sequence)
        print(f"âœ… ç”ŸæˆæŸå¤±: {loss:.4f}")
        
        # æ¨ç†æ¨¡å¼ - ç”Ÿæˆåºåˆ—
        gen_layer.eval()
        with torch.no_grad():
            generated_outputs = gen_layer(
                user_embeddings=user_embeddings[:4],
                item_embeddings=item_embeddings,
                item_text_features=item_text_features,
                item_vision_features=item_vision_features,
                target_items=target_items[:4],
                explanation_tokens=None  # æ¨ç†æ¨¡å¼
            )
        
        print(f"ç”Ÿæˆçš„åºåˆ—:")
        generated_tokens = generated_outputs['generated_tokens']
        for i, seq in enumerate(generated_tokens):
            print(f"  æ ·æœ¬ {i}: {seq[:10].tolist()}...")  # æ˜¾ç¤ºå‰10ä¸ªtoken
        
        # æµ‹è¯•å¤šæ¨¡æ€èåˆ
        print(f"\næµ‹è¯•å¤šæ¨¡æ€èåˆ...")
        fusion = MultiModalFusion(embedding_dim=64, text_dim=384, vision_dim=2048, output_dim=64)
        emb_feat = torch.randn(batch_size, 64)
        text_feat = torch.randn(batch_size, 384)
        vision_feat = torch.randn(batch_size, 2048)
        fused_feat = fusion(emb_feat, text_feat, vision_feat)
        print(f"èåˆç‰¹å¾å½¢çŠ¶: {fused_feat.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå±‚æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_config_system():
    """æµ‹è¯•é…ç½®ç³»ç»Ÿ"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•é…ç½®ç³»ç»Ÿ")
    print("=" * 50)
    
    try:
        sys.path.insert(0, os.path.join(current_dir, 'mig_dpg', 'configs'))
        from mig_dpg_default_config import MIG_DPG_DefaultConfig
        
        # åˆ›å»ºé…ç½®
        config = MIG_DPG_DefaultConfig()
        
        print(f"é»˜è®¤é…ç½®å‚æ•°:")
        print(f"  åµŒå…¥ç»´åº¦: {config.embedding_size}")
        print(f"  å­¦ä¹ ç‡: {config.learning_rate}")
        print(f"  æ‰¹æ¬¡å¤§å°: {config.batch_size}")
        print(f"  DPOå¯ç”¨: {config.dpo_enabled}")
        print(f"  ç”Ÿæˆå¯ç”¨: {config.generation_enabled}")
        print(f"  è®­ç»ƒç­–ç•¥: {config.training_strategy}")
        print(f"  æœ€å¤§åºåˆ—é•¿åº¦: {config.max_seq_length}")
        print(f"  è´Ÿé‡‡æ ·æ¯”ä¾‹: {config.negative_sampling_ratio}")
        
        # æµ‹è¯•é…ç½®ä¿®æ”¹
        config.num_users = 200
        config.num_items = 100
        config.embedding_size = 128
        
        print(f"\nä¿®æ”¹åé…ç½®:")
        print(f"  ç”¨æˆ·æ•°é‡: {config.num_users}")
        print(f"  ç‰©å“æ•°é‡: {config.num_items}")
        print(f"  åµŒå…¥ç»´åº¦: {config.embedding_size}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_simple_dataset():
    """æµ‹è¯•ç®€åŒ–æ•°æ®é›†"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•ç®€åŒ–æ•°æ®é›†")
    print("=" * 50)
    
    try:
        # åˆ›å»ºç®€å•çš„æ•°æ®é›†ç±»
        class SimpleDataset:
            def __init__(self, num_users, num_items, num_interactions=1000):
                self.num_users = num_users
                self.num_items = num_items
                
                # ç”Ÿæˆéšæœºäº¤äº’
                self.interactions = []
                for _ in range(num_interactions):
                    user = np.random.randint(0, num_users)
                    item = np.random.randint(0, num_items)
                    rating = np.random.choice([1, 2, 3, 4, 5])
                    self.interactions.append([user, item, rating])
                
                # ç”Ÿæˆæ¨¡æ‹Ÿç‰¹å¾
                self.user_features = torch.randn(num_users, 64)
                self.item_features = torch.randn(num_items, 64)
                self.item_text_features = torch.randn(num_items, 384)
                self.item_vision_features = torch.randn(num_items, 2048)
            
            def __len__(self):
                return len(self.interactions)
            
            def __getitem__(self, idx):
                user, item, rating = self.interactions[idx]
                
                # è´Ÿé‡‡æ ·
                neg_item = np.random.randint(0, self.num_items)
                while neg_item == item:
                    neg_item = np.random.randint(0, self.num_items)
                
                return {
                    'user': user,
                    'pos_item': item,
                    'neg_item': neg_item,
                    'rating': rating,
                    'user_feat': self.user_features[user],
                    'pos_item_feat': self.item_features[item],
                    'neg_item_feat': self.item_features[neg_item],
                    'pos_text_feat': self.item_text_features[item],
                    'pos_vision_feat': self.item_vision_features[item]
                }
        
        # åˆ›å»ºæ•°æ®é›†
        dataset = SimpleDataset(num_users=100, num_items=50, num_interactions=500)
        
        print(f"æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  ç”¨æˆ·æ•°é‡: {dataset.num_users}")
        print(f"  ç‰©å“æ•°é‡: {dataset.num_items}")
        print(f"  äº¤äº’æ•°é‡: {len(dataset)}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        sample = dataset[0]
        print(f"\næ ·æœ¬æ•°æ®:")
        for key, value in sample.items():
            if torch.is_tensor(value):
                print(f"  {key}: {value.shape}")
            else:
                print(f"  {key}: {value}")
        
        # æµ‹è¯•æ‰¹é‡åŠ è½½
        from torch.utils.data import DataLoader
        dataloader = DataLoader(dataset, batch_size=16, shuffle=True)
        
        batch = next(iter(dataloader))
        print(f"\næ‰¹é‡æ•°æ®å½¢çŠ¶:")
        for key, value in batch.items():
            if torch.is_tensor(value):
                print(f"  {key}: {value.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ MIG-DPG ç»„ä»¶å•ç‹¬æµ‹è¯•")
    print("=" * 60)
    
    results = []
    
    # åŸºç¡€ç¯å¢ƒæµ‹è¯•
    print("CUDAå¯ç”¨:", torch.cuda.is_available())
    print("PyTorchç‰ˆæœ¬:", torch.__version__)
    print("")
    
    # ç»„ä»¶æµ‹è¯•
    results.append(("DPOå±‚", test_dpo_layer_direct()))
    results.append(("ç”Ÿæˆå±‚", test_generation_layer_direct()))
    results.append(("é…ç½®ç³»ç»Ÿ", test_config_system()))
    results.append(("ç®€åŒ–æ•°æ®é›†", test_simple_dataset()))
    
    # ç»“æœæ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{test_name:15} : {status}")
        if success:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æ ¸å¿ƒç»„ä»¶æµ‹è¯•é€šè¿‡ï¼")
        print("âœ¨ å¯ä»¥ç»§ç»­è¿›è¡Œè®­ç»ƒå®éªŒ")
    else:
        print("âš ï¸  éƒ¨åˆ†ç»„ä»¶æµ‹è¯•å¤±è´¥")
    
    return passed == total

if __name__ == "__main__":
    success = main() 