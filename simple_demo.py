#!/usr/bin/env python3
"""
MIG-DPG ç®€åŒ–æ¼”ç¤ºè„šæœ¬
æµ‹è¯•æ ¸å¿ƒç»„ä»¶åŠŸèƒ½ï¼Œé¿å¼€DGLä¾èµ–é—®é¢˜
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import sys
import os
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

def test_dpo_layer():
    """æµ‹è¯•DPOå±‚åŠŸèƒ½"""
    print("=" * 50)
    print("ğŸ§ª æµ‹è¯•DPOåå¥½ä¼˜åŒ–å±‚")
    print("=" * 50)
    
    try:
        from mig_dpg.layers.dpo_layer import DPOLayer
        
        # åˆ›å»ºDPOå±‚
        config = {
            'embedding_size': 64,
            'dpo_hidden_dim': 128,
            'dpo_num_heads': 4,
            'dpo_beta': 0.1
        }
        
        dpo_layer = DPOLayer(config)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 32
        user_emb = torch.randn(batch_size, 64)
        pos_item_emb = torch.randn(batch_size, 64)
        neg_item_emb = torch.randn(batch_size, 64)
        
        print(f"è¾“å…¥å½¢çŠ¶:")
        print(f"  ç”¨æˆ·åµŒå…¥: {user_emb.shape}")
        print(f"  æ­£æ ·æœ¬åµŒå…¥: {pos_item_emb.shape}")
        print(f"  è´Ÿæ ·æœ¬åµŒå…¥: {neg_item_emb.shape}")
        
        # å‰å‘ä¼ æ’­
        dpo_loss = dpo_layer(user_emb, pos_item_emb, neg_item_emb)
        
        print(f"âœ… DPOæŸå¤±: {dpo_loss:.4f}")
        print(f"æŸå¤±å½¢çŠ¶: {dpo_loss.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ DPOå±‚æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_generation_layer():
    """æµ‹è¯•ç”Ÿæˆå±‚åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•ç”Ÿæˆå¼è§£é‡Šå±‚")
    print("=" * 50)
    
    try:
        from mig_dpg.layers.generation_layer import GenerationLayer
        
        # åˆ›å»ºç”Ÿæˆå±‚
        config = {
            'embedding_size': 64,
            'vocab_size': 1000,
            'hidden_dim': 128,
            'num_layers': 2,
            'num_heads': 4,
            'max_seq_length': 50
        }
        
        gen_layer = GenerationLayer(config)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 16
        user_item_emb = torch.randn(batch_size, 64)
        target_tokens = torch.randint(0, 1000, (batch_size, 20))
        
        print(f"è¾“å…¥å½¢çŠ¶:")
        print(f"  ç”¨æˆ·-ç‰©å“åµŒå…¥: {user_item_emb.shape}")
        print(f"  ç›®æ ‡tokens: {target_tokens.shape}")
        
        # å‰å‘ä¼ æ’­ - è®­ç»ƒæ¨¡å¼
        gen_layer.train()
        loss = gen_layer(user_item_emb, target_tokens)
        
        print(f"âœ… ç”ŸæˆæŸå¤±: {loss:.4f}")
        
        # æ¨ç†æ¨¡å¼ - ç”Ÿæˆæ–‡æœ¬
        gen_layer.eval()
        with torch.no_grad():
            generated = gen_layer.generate(user_item_emb[:4], max_length=15)
        
        print(f"ç”Ÿæˆçš„tokenåºåˆ—:")
        for i, seq in enumerate(generated):
            print(f"  æ ·æœ¬ {i}: {seq[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªtoken
        
        return True
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå±‚æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_processor():
    """æµ‹è¯•æ•°æ®å¤„ç†å™¨"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•æ•°æ®å¤„ç†å™¨")
    print("=" * 50)
    
    try:
        from mig_dpg.data_processor import MultiTaskDataset
        
        # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
        num_users, num_items = 100, 50
        interactions = []
        
        # ç”Ÿæˆç”¨æˆ·-ç‰©å“äº¤äº’
        for u in range(num_users):
            num_int = np.random.randint(3, 8)
            items = np.random.choice(num_items, num_int, replace=False)
            for item in items:
                interactions.append([u, item, 1])  # [user, item, rating]
        
        dataset = MultiTaskDataset(
            interactions=interactions,
            num_users=num_users,
            num_items=num_items,
            negative_sampling_ratio=4
        )
        
        print(f"æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  äº¤äº’æ•°é‡: {len(interactions)}")
        print(f"  ç”¨æˆ·æ•°é‡: {num_users}")
        print(f"  ç‰©å“æ•°é‡: {num_items}")
        
        # æµ‹è¯•æ•°æ®åŠ è½½
        sample = dataset[0]
        print(f"æ ·æœ¬æ•°æ®å½¢çŠ¶:")
        for key, value in sample.items():
            if torch.is_tensor(value):
                print(f"  {key}: {value.shape}")
            else:
                print(f"  {key}: {type(value)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†å™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_trainer():
    """æµ‹è¯•è®­ç»ƒå™¨é…ç½®"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•è®­ç»ƒå™¨é…ç½®")
    print("=" * 50)
    
    try:
        from mig_dpg.trainer import MIG_DPG_Trainer
        from mig_dpg.configs.mig_dpg_default_config import MIG_DPG_DefaultConfig
        
        # åˆ›å»ºé…ç½®
        config = MIG_DPG_DefaultConfig()
        config.num_users = 100
        config.num_items = 50
        config.embedding_size = 64
        
        print(f"è®­ç»ƒé…ç½®:")
        print(f"  å­¦ä¹ ç‡: {config.learning_rate}")
        print(f"  æ‰¹æ¬¡å¤§å°: {config.batch_size}")
        print(f"  åµŒå…¥ç»´åº¦: {config.embedding_size}")
        print(f"  DPOå¯ç”¨: {config.dpo_enabled}")
        print(f"  ç”Ÿæˆå¯ç”¨: {config.generation_enabled}")
        print(f"  è®­ç»ƒç­–ç•¥: {config.training_strategy}")
        
        return True
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒå™¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_basic_pytorch():
    """æµ‹è¯•åŸºç¡€PyTorchåŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ§ª æµ‹è¯•åŸºç¡€PyTorchç¯å¢ƒ")
    print("=" * 50)
    
    # æ£€æŸ¥CUDA
    cuda_available = torch.cuda.is_available()
    print(f"CUDAå¯ç”¨: {cuda_available}")
    if cuda_available:
        print(f"CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰CUDAè®¾å¤‡: {torch.cuda.current_device()}")
    
    # åˆ›å»ºç®€å•å¼ é‡æ“ä½œ
    x = torch.randn(100, 64)
    y = torch.randn(64, 32)
    z = torch.mm(x, y)
    
    print(f"å¼ é‡è¿ç®—æµ‹è¯•:")
    print(f"  xå½¢çŠ¶: {x.shape}")
    print(f"  yå½¢çŠ¶: {y.shape}")
    print(f"  zå½¢çŠ¶: {z.shape}")
    print(f"  zå‡å€¼: {z.mean():.4f}")
    
    # æµ‹è¯•ç¥ç»ç½‘ç»œ
    net = nn.Sequential(
        nn.Linear(64, 128),
        nn.ReLU(),
        nn.Linear(128, 32),
        nn.Softmax(dim=1)
    )
    
    output = net(x)
    print(f"ç¥ç»ç½‘ç»œè¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"è¾“å‡ºå’Œ: {output.sum(dim=1)[:5]}")  # softmaxåº”è¯¥å’Œä¸º1
    
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ MIG-DPG ç®€åŒ–åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    results = []
    
    # åŸºç¡€ç¯å¢ƒæµ‹è¯•
    results.append(("PyTorchç¯å¢ƒ", test_basic_pytorch()))
    
    # ç»„ä»¶æµ‹è¯•
    results.append(("DPOå±‚", test_dpo_layer()))
    results.append(("ç”Ÿæˆå±‚", test_generation_layer()))
    results.append(("æ•°æ®å¤„ç†å™¨", test_data_processor()))
    results.append(("è®­ç»ƒå™¨é…ç½®", test_trainer()))
    
    # ç»“æœæ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("=" * 60)
    
    passed = 0
    total = len(results)
    
    for test_name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"{test_name:15} : {status}")
        if success:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MIG-DPGç¯å¢ƒå‡†å¤‡å°±ç»ª")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥ç›¸å…³ç»„ä»¶")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    if success:
        print("\nâœ¨ ä¸‹ä¸€æ­¥å¯ä»¥è¿è¡Œå®Œæ•´çš„è®­ç»ƒå®éªŒ")
    else:
        print("\nğŸ”§ è¯·å…ˆè§£å†³ç¯å¢ƒé—®é¢˜") 